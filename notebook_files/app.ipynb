{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70ce8e8-56f1-43aa-8807-967dcd3d78a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (3.1.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: pyngrok in c:\\users\\shanika\\anaconda3\\lib\\site-packages (7.2.8)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from flask) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shanika\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\Shanika\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py\", line 44, in __getattr__\n",
      "    raise ImportError(msg)\n",
      "ImportError: \n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\Shanika\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py\", line 44, in __getattr__\n",
      "    raise ImportError(msg)\n",
      "ImportError: \n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\Shanika\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Shanika\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\Shanika\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Shanika\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shanika\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py\", line 44, in __getattr__\n",
      "    raise ImportError(msg)\n",
      "ImportError: \n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "\n",
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Shanika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Shanika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install flask tensorflow nltk pyngrok\n",
    "!python -m nltk.downloader punkt wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4acf91ec-430f-42ae-bfb9-74213d8505e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request , jsonify\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a2020-7f93-466a-ad67-fc78e5173ff1",
   "metadata": {},
   "source": [
    "Initialize Flask App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acfebb1-16c4-42ba-8c84-dc058cd36caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder='../templates',static_folder='../static')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0266ada5-5cdb-4b26-803a-256bc53e55a3",
   "metadata": {},
   "source": [
    "load chatbot model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5f6736-8c29-413b-bcb4-a2278a4d7229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading chatbot resources...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot resources loaded succesfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"loading chatbot resources...\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "intents = json.loads(open('intents.json', encoding='utf-8').read())\n",
    "words = pickle.load(open('../words.pkl', 'rb'))\n",
    "classes = pickle.load(open('../classes.pkl', 'rb'))\n",
    "model = load_model('../chatbot_model.h5')\n",
    "print(\"Chatbot resources loaded succesfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a74776-2472-445a-9b2f-1cf2414b5c3b",
   "metadata": {},
   "source": [
    "Chatbot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d50127-2a4a-48ef-8df8-db58e74455f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    return [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0] * len(words)\n",
    "    for w in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "    \n",
    "def predict_class(sentence):\n",
    "    bow = bag_of_words(sentence)\n",
    "    res = model.predict(np.array([bow]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
    "    return return_list\n",
    "    \n",
    "def get_response(intents_list, intents_json):\n",
    "    tag = intents_list[0]['intent']\n",
    "    for i in intents_json['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            return random.choice(i['responses'])\n",
    "    return \"I'm not sure I understand. Could you rephrase that?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbc261-058f-473c-97a8-7fbbb9d586ed",
   "metadata": {},
   "source": [
    "Flask Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8783218a-c7b9-4eda-a26c-8f5b679b1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/get_response', methods=['POST'])\n",
    "def get_bot_response():\n",
    "    user_message = request.json['message']\n",
    "    ints = predict_class(user_message)\n",
    "    response = get_response(ints, intents)\n",
    "    return jsonify({'response': response})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82d10f-5320-431e-9ab8-48689e583e84",
   "metadata": {},
   "source": [
    "Run Flask App with Ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f5c91-b83c-4d98-855f-b2ef768c38b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyngrok.process.ngrok:t=2025-05-26T09:47:38+0530 lvl=warn msg=\"invalid tunnel configuration\" pg=/api/tunnels id=be5534785465227b err=\"yaml: unmarshal errors:\\n  line 1: field region not found in type config.HTTPv2Tunnel\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Ngrok connection failed: ngrok client exception, API returned 400: {\"error_code\":102,\"status_code\":400,\"msg\":\"invalid tunnel configuration\",\"details\":{\"err\":\"yaml: unmarshal errors:\\n  line 1: field region not found in type config.HTTPv2Tunnel\"}}\n",
      "\n",
      " * Running locally only (accessible via http://localhost:5000)\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.126.226:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:50:46] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:50:46] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:50:46] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:50:46] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:51:01] \"POST /get_response HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:51:19] \"POST /get_response HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:52:15] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:52:15] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:52:16] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:52:40] \"POST /get_response HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:53:27] \"POST /get_response HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 09:54:41] \"POST /get_response HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:02:53] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:02:53] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:02:53] \"GET /static/script.js HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:03:27] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:03:27] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:03:27] \"GET /static/script.js HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:03:51] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:03:51] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:03:51] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:04:00] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:04:00] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:04:01] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:08:18] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:08:18] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:08:18] \"GET /static/script.js HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:10:30] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:10:30] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:10:30] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:11:06] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:11:06] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:11:06] \"GET /static/script.js HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:11:58] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:11:58] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:11:58] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:12:18] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:12:19] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:12:19] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:08] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:08] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:08] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:28] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:28] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:28] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:58] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:58] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:14:58] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:16:17] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:16:17] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:16:17] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:16:57] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:16:57] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:16:57] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:18:33] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:18:35] \"\u001b[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:19:40] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:19:40] \"\u001b[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:19:41] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:19:41] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:20:04] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:20:04] \"\u001b[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:20:04] \"GET /static/style.css HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:20:04] \"\u001b[36mGET /static/script.js HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:20:14] \"POST /get_response HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/May/2025 10:20:22] \"POST /get_response HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Run Flask App with Ngrok (Updated)\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # Configure ngrok with alternative region\n",
    "        ngrok.set_auth_token(\"2xZgWkaSN7aIb1DxtGZ0p8Hpk1d_24Hv9XVQfafrGduqVoPgK\")  \n",
    "        public_url = ngrok.connect(5000, region='ap') \n",
    "        print(f\"\\n * Public URL: {public_url}\")\n",
    "        print(\" * This URL can be used to access your app from anywhere\")\n",
    "        print(\" * Use this for WhatsApp webhook if needed\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n * Ngrok connection failed: {str(e)}\")\n",
    "        print(\" * Running locally only (accessible via http://localhost:5000)\\n\")\n",
    "    \n",
    "    # Run Flask app\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223c806-7c41-4e63-841a-fa5634c3b8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249676f-65be-4332-95cf-cdbdc91c062d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
